{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whats here?\n",
    "- Possibility to load and prompt the gemma2 model directly without HOOKS\n",
    "- Most Gemma 2 up to 9B pars work on RTX3070 -- time taken, see below\n",
    "- Loading different datasets \n",
    "- Ask multiple Qs from Datasets\n",
    "- write answers to .csv (buggy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Conda Env == lets_drift_env_V1 \n",
    "(Which is a clone of arena_env1_1_1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for Gemma Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = t.device('mps' if t.backends.mps.is_available() else 'cuda' if t.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e44b35a11242cf928959baa3f5eebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()  # This will prompt for your HuggingFace token in a text box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starts with a j..jeje .. f_JTQGGDeycTxPCozthrzqWQhmLpOkaVKXRq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Clear any loaded models from RAM ~~ alternatively restart the kernel\\nimport gc\\n\\n\\nif 'model' in locals() or 'model' in globals():\\n    del model\\nif 'tokenizer' in locals() or 'tokenizer' in globals():\\n    del tokenizer\\n    \\ngc.collect()\\nt.cuda.empty_cache() if t.cuda.is_available() else None \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Clear any loaded models from RAM ~~ alternatively restart the kernel\n",
    "import gc\n",
    "\n",
    "\n",
    "if 'model' in locals() or 'model' in globals():\n",
    "    del model\n",
    "if 'tokenizer' in locals() or 'tokenizer' in globals():\n",
    "    del tokenizer\n",
    "    \n",
    "gc.collect()\n",
    "t.cuda.empty_cache() if t.cuda.is_available() else None \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e228e116af754fdb9091d98112333f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma2_9b_it loaded\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model2use = \"gemma2_9b_it\"#\"gemma2_2b_it\"\n",
    "\n",
    "\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b\", device_map=\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a **quick test** that the model is working with a random prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Once upon a time, \n",
      "in a land where the sun always shone,\n",
      "lived a little girl named Lily.\n",
      "\n",
      "Lily had hair like spun gold,\n",
      "eyes as blue as the summer sky,\n",
      "and a smile that could light up the darkest night.\n",
      "\n",
      "But Lily was lonely.\n",
      "\n",
      "She had no one to play with,\n",
      "no one to share her secrets with,\n",
      "no one to laugh with.\n",
      "\n",
      "One day, while wandering through the forest,\n",
      "Lily stumbled upon a tiny, shimmering door.\n",
      "\n",
      "It was no bigger than her hand,\n",
      "and it was made of the most beautiful crystal.\n",
      "\n",
      "Curiosity got the better of her,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_text = \"Once upon a time, \"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=64)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to make history based contextualization .... (ie use past prompts and answers in it's new answer..)\n",
    "\n",
    "https://jaswanth04.medium.com/history-based-contextualization-in-llm-deployed-as-a-backend-service-fastapi-and-5a1759fdd32e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput_text = \"What did I last ask you?\"\\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\\n\\noutputs = model.generate(**input_ids, max_new_tokens=128)\\nprint(tokenizer.decode(outputs[0]))'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "input_text = \"What did I last ask you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=128)\n",
    "print(tokenizer.decode(outputs[0]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans= tokenizer.decode(outputs[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos>Once upon a time, \\nin a land where the sun always shone,\\nlived a little girl named Lily.\\n\\nLily had hair like spun gold,\\neyes as blue as the summer sky,\\nand a smile that could light up the darkest night.\\n\\nBut Lily was lonely.\\n\\nShe had no one to play with,\\nno one to share her secrets with,\\nno one to laugh with.\\n\\nOne day, while wandering through the forest,\\nLily stumbled upon a tiny, shimmering door.\\n\\nIt was no bigger than her hand,\\nand it was made of the most beautiful crystal.\\n\\nCuriosity got the better of her,\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for Experiment (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment (1) Implementation of the test data from Paper: \"How is ChatGPT's performance change over time?\"\n",
    "\n",
    "Both Gemma 2 2B and 9B work fine. Only the IT (instruction trained) versions give good answers. Both say stuff that they think is right, but it's not. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder of git: GIT_HowIsChatGPTChanging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not used\\n# Load CSV file with prompts and expected answers from paper\\ndef load_test_data(csv_path):\\n    return pd.read_csv(csv_path)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"not used\n",
    "# Load CSV file with prompts and expected answers from paper\n",
    "def load_test_data(csv_path):\n",
    "    return pd.read_csv(csv_path)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HOTPOTQA evaluation data and extract relevant columns\n",
    "hotpotqa_df = pd.read_csv(\"GIT_HowIsChatGPTChanging/LLMDrift/generation/HOTPOTQA_EVAL.csv\") ## HotPotQA is supposed to be a dataset for testing LLMs, \n",
    "# specifically for testing the reasoning steps. https://arxiv.org/pdf/2312.04511#:~:text=Scott%20Derrickson%20(born%20July%2016,1966)%20is%20an%20American%20filmmaker%20%E2%80%A6&text=Search%20Tool-,Observation%3A%20%E2%80%A6,American%20filmmaker%2C%20actor%2C%20and%20%E2%80%A6\n",
    "max_queries=2\n",
    "test_data = hotpotqa_df[['query', 'ref_answer', 'answer']].head(max_queries).copy() # TEST: 5 rows only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data['answer'].iloc[0]\n",
    "#test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 32\n",
    "# Function to generate response from Gemma\n",
    "def generate_gemma_response(prompt, model, tokenizer, max_tokens=256):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**input_ids, max_new_tokens=max_tokens)\n",
    "    return tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_gemma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Convert results to DataFrame\u001b[39;00m\n\u001b[0;32m     25\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m, in \u001b[0;36mevaluate_gemma\u001b[1;34m(test_data, model, tokenizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m query \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# adjust column name based on your CSV structure\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ref_answer \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref_answer\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# adjust column name based on your CSV structure\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m actual_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_gemma_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m: query,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref_answer\u001b[39m\u001b[38;5;124m'\u001b[39m: ref_answer,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m'\u001b[39m: actual_response,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(idx) \u001b[38;5;66;03m# Convert to int for JSON serialization\u001b[39;00m\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx: \u001b[39m\u001b[38;5;124m\"\u001b[39m,idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m result: \u001b[39m\u001b[38;5;124m\"\u001b[39m, result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m ref_answer: \u001b[39m\u001b[38;5;124m\"\u001b[39m, ref_answer)\n",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m, in \u001b[0;36mgenerate_gemma_response\u001b[1;34m(prompt, model, tokenizer, max_tokens)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_gemma_response\u001b[39m(prompt, model, tokenizer, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m):\n\u001b[0;32m      4\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Maximus\\.conda\\envs\\lets_drift_env_V1\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py:2084\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2079\u001b[0m     inputs_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m input_ids_length\n\u001b[0;32m   2080\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model_input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2081\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder\n\u001b[0;32m   2082\u001b[0m ):\n\u001b[0;32m   2083\u001b[0m     max_cache_length \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m inputs_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 2084\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_cache_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_cache_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m   2086\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2088\u001b[0m \u001b[38;5;66;03m# 8. determine generation mode\u001b[39;00m\n\u001b[0;32m   2089\u001b[0m generation_mode \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mget_generation_mode(assistant_model)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py:1731\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_cache_for_generation\u001b[1;34m(self, generation_config, model_kwargs, assistant_model, batch_size, max_cache_length, device)\u001b[0m\n\u001b[0;32m   1726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mcache_implementation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatic\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supports_static_cache:\n\u001b[0;32m   1727\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1728\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model does not support `cache_implementation=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`. Please check the following \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue: https://github.com/huggingface/transformers/issues/28981\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1730\u001b[0m         )\n\u001b[1;32m-> 1731\u001b[0m     model_kwargs[cache_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_implementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_cache_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_cache_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mcache_implementation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantized\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supports_quantized_cache:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py:1622\u001b[0m, in \u001b[0;36mGenerationMixin._get_cache\u001b[1;34m(self, cache_implementation, batch_size, max_cache_len, device, model_kwargs)\u001b[0m\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;66;03m# Taken from dispatch_model from accelerate.\u001b[39;00m\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;66;03m# This is needed here if we don't want to make changes in accelerate in order to save execution_device\u001b[39;00m\n\u001b[0;32m   1620\u001b[0m \u001b[38;5;66;03m# For offloaded case, we need to get the execution device, not just the device where it is offloaded\u001b[39;00m\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_device_map\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1622\u001b[0m     main_device \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_device_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1623\u001b[0m     execution_device_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1624\u001b[0m         name: main_device \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m device\n\u001b[0;32m   1625\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name, device \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_device_map\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1626\u001b[0m     }\n\u001b[0;32m   1627\u001b[0m layer_device_map \u001b[38;5;241m=\u001b[39m get_layer_device_map(execution_device_map)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Function to run evaluation\n",
    "def evaluate_gemma(test_data, model, tokenizer):\n",
    "    results = []\n",
    "    for idx, row in test_data.iterrows():\n",
    "        query = row['query']  # adjust column name based on your CSV structure\n",
    "        ref_answer = row['ref_answer']  # adjust column name based on your CSV structure\n",
    "        \n",
    "        actual_response = generate_gemma_response(query, model, tokenizer)\n",
    "        \n",
    "        result = {\n",
    "            'query': query,\n",
    "            'ref_answer': ref_answer,\n",
    "            'actual': actual_response,\n",
    "            'prompt_id': int(idx) # Convert to int for JSON serialization\n",
    "        }\n",
    "        print(\"idx: \",idx, \"\\n result: \", result, \"\\n ref_answer: \", ref_answer)\n",
    "        results.append(result)\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate_gemma(test_data, model, tokenizer)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Save results to JSONL\n",
    "import json\n",
    "output_path = f\"{model2use}_results.jsonl\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for result in results:\n",
    "        json.dump(result, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "print(f\"Results saved to {output_path}\")\n",
    "\"\"\"\n",
    "# Save results to CSV\n",
    "output_path = f\"{model_name}_results.csv\"\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"Results saved to {output_path}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above eval script takes 2min 9s for 2 prompts with max tokens == 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in test_data.iterrows():\n",
    "    print(row['query'], idx )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying a new Dataset, Natural Questions, Google AI [MAYBE come back to it]\n",
    "HotPotQA is straightforward for usage, so stick with that for now, although the hotpotQA is almost too difficult for SAE Resaearch, it's designed to reason answers based on step-by-step thinking. The following NQ dataset is quite simple; It's Q's asked by google's users and their answers (in long and short format, as well as multiple answers for some Q where multiple answers are applicable)\n",
    "\n",
    "-->Note; NQ is not that easy to use.. answers are formed by saying 'word #x to #y of this mega text have the answer in short, long, or alternative..'.. Will need some scripting effort!!\n",
    "\n",
    "Eval script available here, as well as a way to 'unsimplify' the answers in the 4GB dataset\n",
    "https://github.com/google-research-datasets/natural-questions/blob/master/nq_eval.py\n",
    "Simple Dataset is downloaded from: https://ai.google.com/research/NaturalQuestions/download "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial run: loads first 3 rows (HUGE file 4GB) (takes 1 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing imports ...\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_partial_jsonl(file_path, num_rows=10):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= num_rows:\n",
    "                break\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load first few rows of the Natural Questions dataset\n",
    "nq_df = load_partial_jsonl('NaturalQuestions_GoogleAI/simplified-nq-train.jsonl', num_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "document_text:\n",
      "Email marketing - Wikipedia <H1> Email marketing </H1> Jump to : navigation , search <Table> <Tr> <Td> </Td> <Td> ( hide ) This article has multiple issues . Please help improve it or discuss these issues on the talk page . ( Learn how and when to remove these template messages ) <Table> <Tr> <Td> </Td> <Td> This article needs additional citations for verification . Please help improve this article by adding citations to reliable sources . Unsourced material may be challenged and removed . ( September 2014 ) ( Learn how and when to remove this template message ) </Td> </Tr> </Table> <Table> <Tr> <Td> </Td> <Td> This article possibly contains original research . Please improve it by verifying the claims made and adding inline citations . Statements consisting only of original research should be removed . ( January 2015 ) ( Learn how and when to remove this template message ) </Td> </Tr> </Table> ( Learn how and when to remove this template message ) </Td> </Tr> </Table> <Table> <Tr> <Td> Part of a series on </Td> </Tr> <Tr> <Th> Internet marketing </Th> </Tr> <Tr> <Td> <Ul> <Li> Search engine optimization </Li> <Li> Local search engine optimisation </Li> <Li> Social media marketing </Li> <Li> Email marketing </Li> <Li> Referral marketing </Li> <Li> Content marketing </Li> <Li> Native advertising </Li> </Ul> </Td> </Tr> <Tr> <Th> Search engine marketing </Th> </Tr> <Tr> <Td> <Ul> <Li> Pay - per - click </Li> <Li> Cost per impression </Li> <Li> Search analytics </Li> <Li> Web analytics </Li> </Ul> </Td> </Tr> <Tr> <Th> Display advertising </Th> </Tr> <Tr> <Td> <Ul> <Li> Ad blocking </Li> <Li> Contextual advertising </Li> <Li> Behavioral targeting </Li> </Ul> </Td> </Tr> <Tr> <Th> Affiliate marketing </Th> </Tr> <Tr> <Td> <Ul> <Li> Cost per action </Li> <Li> Revenue sharing </Li> </Ul> </Td> </Tr> <Tr> <Th> Mobile advertising </Th> </Tr> <Tr> <Td> <Ul> <Li> </Li> <Li> </Li> <Li> </Li> </Ul> </Td> </Tr> </Table> <P> Email marketing is the act of sending a commercial message , typically to a group of people , using email . In its broadest sense , every email sent to a potential or current customer could be considered email marketing . It usually involves using email to send advertisements , request business , or solicit sales or donations , and is meant to build loyalty , trust , or brand awareness . Marketing emails can be sent to a purchased lead list or a current customer database . The term usually refers to sending email messages with the purpose of enhancing a merchant 's relationship with current or previous customers , encouraging customer loyalty and repeat business , acquiring new customers or convincing current customers to purchase something immediately , and sharing third - party ads . </P> <P> </P> <H2> Contents </H2> ( hide ) <Ul> <Li> 1 History </Li> <Li> 2 Types <Ul> <Li> 2.1 Transactional emails </Li> <Li> 2.2 Direct emails <Ul> <Li> 2.2. 1 Mobile email marketing </Li> </Ul> </Li> </Ul> </Li> <Li> 3 Comparison to traditional mail <Ul> <Li> 3.1 Advantages </Li> <Li> 3.2 Disadvantages </Li> </Ul> </Li> <Li> 4 Opt - in email advertising </Li> <Li> 5 Legal requirements <Ul> <Li> 5.1 Australia </Li> <Li> 5.2 Canada </Li> <Li> 5.3 European Union </Li> <Li> 5.4 United States </Li> </Ul> </Li> <Li> 6 See also </Li> <Li> 7 References </Li> </Ul> <P> </P> <H2> History </H2> <P> Email marketing has evolved rapidly alongside the technological growth of the 21st century . Prior to this growth , when emails were novelties to the majority of customers , email marketing was not as effective . In 1978 , Gary Thuerk of Digital Equipment Corporation ( DEC ) sent out the first mass email to approximately 400 potential clients via the Advanced Research Projects Agency Network ( ARPANET ) . This email resulted in $13 million worth of sales in DEC products , and highlighted the potential of marketing through mass emails . However , as email marketing developed as an effective means of direct communication , users began blocking out content from emails with filters and blocking programs . In order to effectively communicate a message through email , marketers had to develop a way of pushing content through to the end user , without being cut out by automatic filters and spam removing software . This resulted in the birth of triggered marketing emails , which are sent to specific users based on their tracked online browsing patterns . </P> <P> Historically , it has been difficult to measure the effectiveness of marketing campaigns because target markets can not be adequately defined . Email marketing carries the benefit of allowing marketers to identify returns on investment and measure and improve efficiency . Email marketing allows marketers to see feedback from users in real time , and to monitor how effective their campaign is in achieving market penetration , revealing a communication channel 's scope . At the same time , however , it also means that the more personal nature of certain advertising methods , such as television advertisements , can not be captured . </P> <H2> Types </H2> <P> Email marketing can be carried out through different types of emails : </P> <H3> Transactional emails </H3> <P> Transactional emails are usually triggered based on a customer 's action with a company . To be qualified as transactional or relationship messages , these communications ' primary purpose must be `` to facilitate , complete , or confirm a commercial transaction that the recipient has previously agreed to enter into with the sender '' along with a few other narrow definitions of transactional messaging . Triggered transactional messages include dropped basket messages , password reset emails , purchase or order confirmation emails , order status emails , reorder emails , and email receipts . </P> <P> The primary purpose of a transactional email is to convey information regarding the action that triggered it . But , due to their high open rates ( 51.3 % compared to 36.6 % for email newsletters ) , transactional emails are an opportunity to introduce or extend the email relationship with customers or subscribers ; to anticipate and answer questions ; or to cross-sell or up - sell products or services . </P> <P> Many email newsletter software vendors offer transactional email support , which gives companies the ability to include promotional messages within the body of transactional emails . There are also software vendors that offer specialized transactional email marketing services , which include providing targeted and personalized transactional email messages and running specific marketing campaigns ( such as customer referral programs ) . </P> <H3> Direct emails </H3> <P> Direct email involves sending an email solely to communicate a promotional message ( for example , a special offer or a product catalog ) . Companies usually collect a list of customer or prospect email addresses to send direct promotional messages to , or they rent a list of email addresses from service companies . Safe mail marketing is also used . </P> Mobile email marketing <P> Email marketing develops large amounts of traffic through smartphones and tablets . Marketers are researching ways to advertise to more users and to make them view advertising for longer . However , the rate of delivery is still relatively low due to better filtering - out of advertising and users having multiple email accounts for different purposes . Because emails are generated according to the tracked behavior of consumers , it is possible to send advertising which is based on the recipient 's behavior . Because of this , modern email marketing is perceived more often as a pull strategy rather than a push strategy . </P> <H2> Comparison to traditional mail </H2> <P> There are both advantages and disadvantages to using email marketing in comparison to traditional advertising mail . </P> <H3> Advantages </H3> <P> Email marketing is popular with companies for several reasons : </P> <Ul> <Li> An exact return on investment can be tracked ( `` track to basket '' ) and has proven to be high when done properly . Email marketing is often reported as second only to search marketing as the most effective online marketing tactic . </Li> <Li> Email marketing is significantly cheaper and faster than traditional mail , mainly because of the high cost and time required in a traditional mail campaign for producing the artwork , printing , addressing , and mailing . </Li> <Li> Businesses and organizations who send a high volume of emails can use an ESP ( email service provider ) to gather information about the behavior of the recipients . The insights provided by consumer response to email marketing help businesses and organizations understand and make use of consumer behavior . </Li> <Li> Email provides a cost - effective method to test different marketing content , including visual , creative , marketing copy , and multimedia assets . The data gathered by testing in the email channel can then be used across all channels of marketing campaigns , both print and digital . </Li> <Li> Advertisers can reach substantial numbers of email subscribers who have opted in ( i.e. , consented ) to receive the email . </Li> <Li> Almost half of American Internet users check or send email on a typical day , with emails delivered between 1 am and 5 am local time outperforming those sent at other times in open and click rates . </Li> <Li> Email is popular with digital marketers , rising an estimated 15 % in 2009 to £ 292 million in the UK . </Li> <Li> If compared to standard email , direct email marketing produces higher response rate and higher average order value for e-commerce businesses . </Li> </Ul> <H3> Disadvantages </H3> <P> As of mid-2016 email deliverability is still an issue for legitimate marketers . According to the report , legitimate email servers averaged a delivery rate of 73 % in the U.S. ; six percent were filtered as spam , and 22 % were missing . This lags behind other countries : Australia delivers at 90 % , Canada at 89 % , Britain at 88 % , France at 84 % , Germany at 80 % and Brazil at 79 % . </P> <P> Additionally , consumers receive on average circa 90 emails per day . </P> <P> Companies considering the use of an email marketing program must make sure that their program does not violate spam laws such as the United States ' Controlling the Assault of Non-Solicited Pornography and Marketing Act ( CAN - SPAM ) , the European Privacy and Electronic Communications Regulations 2003 , or their Internet service provider 's acceptable use policy . </P> <H2> Opt - in email advertising </H2> <P> Opt - in email advertising , or permission marketing , is a method of advertising via email whereby the recipient of the advertisement has consented to receive it . This method is one of several developed by marketers to eliminate the disadvantages of email marketing . </P> <P> Opt - in email marketing may evolve into a technology that uses a handshake protocol between the sender and receiver . This system is intended to eventually result in a high degree of satisfaction between consumers and marketers . If opt - in email advertising is used , the material that is emailed to consumers will be `` anticipated '' . It is assumed that the recipient wants to receive it , which makes it unlike unsolicited advertisements sent to the consumer . Ideally , opt - in email advertisements will be more personal and relevant to the consumer than untargeted advertisements . </P> <P> A common example of permission marketing is a newsletter sent to an advertising firm 's customers . Such newsletters inform customers of upcoming events or promotions , or new products . In this type of advertising , a company that wants to send a newsletter to their customers may ask them at the point of purchase if they would like to receive the newsletter . </P> <P> With a foundation of opted - in contact information stored in their database , marketers can send out promotional materials automatically using autoresponders -- known as drip marketing . They can also segment their promotions to specific market segments . </P> <H2> Legal requirements </H2> <H3> Australia </H3> <P> The Australian Spam Act 2003 is enforced by the Australian Communications and Media Authority , widely known as `` ACMA '' . The act defines the term unsolicited electronic messages , states how unsubscribe functions must work for commercial messages , and gives other key information . Fines range with 3 fines of AU $110,000 being issued to Virgin Blue Airlines ( 2011 ) , Tiger Airways Holdings Limited ( 2012 ) and Cellar master Wines Pty Limited ( 2013 ) . </P> <H3> Canada </H3> <P> The `` Canada Anti-Spam Law '' ( CASL ) went into effect on July 1 , 2014 . CASL requires an explicit or implicit opt - in from users , and the maximum fines for noncompliance are CA $ 1 million for individuals and $10 million for businesses . </P> <H3> European Union </H3> <P> In 2002 the European Union ( EU ) introduced the Directive on Privacy and Electronic Communications . Article 13 of the Directive prohibits the use of personal email addresses for marketing purposes . The Directive establishes the opt - in regime , where unsolicited emails may be sent only with prior agreement of the recipient ; this does not apply to business email addresses . </P> <P> The directive has since been incorporated into the laws of member states . In the UK it is covered under the Privacy and Electronic Communications ( EC Directive ) Regulations 2003 and applies to all organizations that send out marketing by some form of electronic communication . </P> <H3> United states </H3> <P> The CAN - SPAM Act of 2003 was passed by Congress as a direct response of the growing number of complaints over spam e-mails . Congress determined that the US government was showing an increased interest in the regulation of commercial electronic mail nationally , that those who send commercial e-mails should not mislead recipients over the source or content of them , and that all recipients of such emails have a right to decline them . The act authorizes a US $16,000 penalty per violation for spamming each individual recipient . However , it does not ban spam emailing outright , but imposes laws on using deceptive marketing methods through headings which are `` materially false or misleading '' . In addition there are conditions which email marketers must meet in terms of their format , their content and labeling . As a result , many commercial email marketers within the United States utilize a service or special software to ensure compliance with the act . A variety of older systems exist that do not ensure compliance with the act . To comply with the act 's regulation of commercial email , services also typically require users to authenticate their return address and include a valid physical address , provide a one - click unsubscribe feature , and prohibit importing lists of purchased addresses that may not have given valid permission . </P> <P> In addition to satisfying legal requirements , email service providers ( ESPs ) began to help customers establish and manage their own email marketing campaigns . The service providers supply email templates and general best practices , as well as methods for handling subscriptions and cancellations automatically . Some ESPs will provide insight and assistance with deliverability issues for major email providers . They also provide statistics pertaining to the number of messages received and opened , and whether the recipients clicked on any links within the messages . </P> <P> The CAN - SPAM Act was updated with some new regulations including a no - fee provision for opting out , further definition of `` sender '' , post office or private mail boxes count as a `` valid physical postal address '' and definition of `` person '' . These new provisions went into effect on July 7 , 2008 . </P> <H2> See also </H2> <Ul> <Li> CAUCE -- Coalition Against Unsolicited Commercial Email </Li> <Li> Customer engagement </Li> <Li> Suppression list </Li> <Li> Email spam - Unsolicited email marketing </Li> </Ul> <H2> References </H2> <Ol> <Li> Jump up ^ `` spam unsolicited e-mail '' . Retrieved September 19 , 2016 . </Li> <Li> Jump up ^ `` PUBLIC LAW 108 -- 187 -- DEC . 16 , 2003 117 STAT. 2699 '' ( PDF ) . U.S Government GPO . </Li> <Li> Jump up ^ ADIKESAVAN , T. MANAGEMENT INFORMATION SYSTEMS BEST PRACTICES AND APPLICATIONS IN BUSINESS . ISBN 8120348966 . Retrieved July 10 , 2015 . </Li> <Li> Jump up ^ MECLABS , content : MarketingSherpa , design : Scott McDaniel , code : Steve Beger , ( January 21 , 2009 ) . `` New Survey Data : Email 's ROI Makes Tactic Key for Marketers in 2009 '' . MarketingSherpa.com . Retrieved August 12 , 2017 . </Li> <Li> Jump up ^ Pew Internet & American Life Project , `` Tracking surveys '' , March 2000 -- March 2009 </Li> <Li> Jump up ^ How Scheduling Affects Rates . Mailermailer.com ( July 2012 ) . Retrieved on July 28 , 2013 . </Li> <Li> Jump up ^ BtoB Magazine , `` Early Email Blasts Results in Higher Click & Open Rates '' Archived 2011 - 11 - 22 at the Wayback Machine. , September 2011 </Li> <Li> Jump up ^ UK e-mail marketing predicted to rise 15 % . MediaWeek.co.uk ( 13 October 2009 ) </Li> <Li> Jump up ^ `` Why Email Marketing is King '' . Harvard Business Review ( 21 August 2012 ) </Li> <Li> Jump up ^ Roberts , A. `` Email deliverability is on the decline : report '' , ClickZ </Li> <Li> Jump up ^ Radicati , Sara . `` Email Statistics Report , 2014 - 2018 '' ( PDF ) . The Radicati Group , Inc . </Li> <Li> Jump up ^ `` Consumer Information '' . Consumer Information . Retrieved August 12 , 2017 . </Li> <Li> ^ Jump up to : Fairhead , N. ( 2003 ) `` All hail the brave new world of permission marketing via email '' ( Media 16 , August 2003 ) </Li> <Li> Jump up ^ Dilworth , Dianna ( 2007 ) . `` Ruth 's Chris Steak House sends sizzling e-mails for special occasions '' . DMNews . Retrieved February 19 , 2008 . </Li> <Li> Jump up ^ O'Brian J. & Montazemia , A. ( 2004 ) Management Information Systems ( Canada : McGraw - Hill Ryerson Ltd . ) </Li> <Li> Jump up ^ `` Spam : enforcement actions '' . Australian Communications and Media Authority . Australian Communications and Media Authority . Archived from the original on February 29 , 2016 . Retrieved August 15 , 2015 . </Li> <Li> Jump up ^ Moorcraft , Bethan . `` Law could force idle brokers back to dark ages '' . Insurance Business . Retrieved August 12 , 2017 . </Li> <Li> Jump up ^ `` Canada 's law on spam '' . Government of Canada . Retrieved July 19 , 2014 ... </Li> <Li> Jump up ^ The Privacy and Electronic Communications ( EC Directive ) Regulations 2003 Archived November 14 , 2006 , at the Wayback Machine ... Opsi.gov.uk . Retrieved on July 28 , 2013 . </Li> <Li> Jump up ^ `` CAN - SPAM Act : A Compliance Guide for Business '' . FTC.gov . BCP Business Center . Retrieved August 10 , 2017 . </Li> <Li> Jump up ^ `` FTC Approves New Rule Provision Under The CAN - SPAM Act '' . FTC.gov . June 24 , 2011 . </Li> <Li> Jump up ^ `` 16 CFR Part 316 Definitions and Implementation Under the CAN -- SPAM Act ; Final Rule '' ( PDF ) . FTC.gov . May 21 , 2008 . </Li> </Ol> Retrieved from `` https://en.wikipedia.org/w/index.php?title=Email_marketing&oldid=814071202 '' Categories : <Ul> <Li> Advertising by medium </Li> <Li> Email </Li> <Li> Digital marketing </Li> <Li> Market research </Li> <Li> Marketing techniques </Li> <Li> Online advertising </Li> <Li> Spamming </Li> </Ul> Hidden categories : <Ul> <Li> Webarchive template wayback links </Li> <Li> Wikipedia indefinitely semi-protected pages </Li> <Li> Articles needing additional references from September 2014 </Li> <Li> All articles needing additional references </Li> <Li> Articles that may contain original research from January 2015 </Li> <Li> All articles that may contain original research </Li> <Li> Articles with multiple maintenance issues </Li> <Li> All articles with unsourced statements </Li> <Li> Articles with unsourced statements from August 2017 </Li> <Li> Articles with unsourced statements from July 2015 </Li> <Li> All Wikipedia articles needing clarification </Li> <Li> Wikipedia articles needing clarification from August 2017 </Li> <Li> Articles with unsourced statements from March 2016 </Li> </Ul> <H2> </H2> <H3> </H3> <Ul> <Li> </Li> <Li> Talk </Li> <Li> </Li> <Li> </Li> <Li> </Li> </Ul> <H3> </H3> <Ul> <Li> </Li> <Li> </Li> </Ul> <H3> </H3> <Ul> </Ul> <H3> </H3> <Ul> <Li> </Li> <Li> View source </Li> <Li> </Li> </Ul> <H3> </H3> <Ul> </Ul> <H3> </H3> <H3> </H3> <Ul> <Li> </Li> <Li> Contents </Li> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> </Ul> <H3> </H3> <Ul> <Li> </Li> <Li> About Wikipedia </Li> <Li> </Li> <Li> </Li> <Li> </Li> </Ul> <H3> </H3> <Ul> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> </Ul> <H3> </H3> <Ul> <Li> </Li> <Li> </Li> <Li> </Li> </Ul> <H3> </H3> <Ul> <Li> </Li> <Li> বাংলা </Li> <Li> Български </Li> <Li> Català </Li> <Li> Čeština </Li> <Li> Español </Li> <Li> فارسی </Li> <Li> Français </Li> <Li> Italiano </Li> <Li> ಕನ್ನಡ </Li> <Li> ქართული </Li> <Li> Македонски </Li> <Li> Nederlands </Li> <Li> 日本 語 </Li> <Li> Norsk </Li> <Li> Polski </Li> <Li> Português </Li> <Li> Русский </Li> <Li> Српски / srpski </Li> <Li> Svenska </Li> <Li> தமிழ் </Li> <Li> తెలుగు </Li> <Li> ไทย </Li> <Li> Türkçe </Li> <Li> Українська </Li> <Li> Tiếng Việt </Li> <Li> 中文 </Li> 18 more </Ul> Edit links <Ul> <Li> This page was last edited on 6 December 2017 , at 19 : 06 . </Li> <Li> </Li> </Ul> <Ul> <Li> </Li> <Li> About Wikipedia </Li> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> <Li> </Li> </Ul> <Ul> <Li> </Li> <Li> </Li> </Ul>\n",
      "\n",
      "long_answer_candidates:\n",
      "[{'start_token': 14, 'top_level': True, 'end_token': 170}, {'start_token': 15, 'top_level': False, 'end_token': 169}, {'start_token': 52, 'top_level': False, 'end_token': 103}, {'start_token': 53, 'top_level': False, 'end_token': 102}, {'start_token': 103, 'top_level': False, 'end_token': 156}, {'start_token': 104, 'top_level': False, 'end_token': 155}, {'start_token': 170, 'top_level': True, 'end_token': 321}, {'start_token': 171, 'top_level': False, 'end_token': 180}, {'start_token': 180, 'top_level': False, 'end_token': 186}, {'start_token': 186, 'top_level': False, 'end_token': 224}, {'start_token': 188, 'top_level': False, 'end_token': 222}, {'start_token': 189, 'top_level': False, 'end_token': 194}, {'start_token': 194, 'top_level': False, 'end_token': 200}, {'start_token': 200, 'top_level': False, 'end_token': 205}, {'start_token': 224, 'top_level': False, 'end_token': 231}, {'start_token': 231, 'top_level': False, 'end_token': 257}, {'start_token': 233, 'top_level': False, 'end_token': 255}, {'start_token': 234, 'top_level': False, 'end_token': 241}, {'start_token': 241, 'top_level': False, 'end_token': 246}, {'start_token': 257, 'top_level': False, 'end_token': 263}, {'start_token': 263, 'top_level': False, 'end_token': 281}, {'start_token': 265, 'top_level': False, 'end_token': 279}, {'start_token': 281, 'top_level': False, 'end_token': 287}, {'start_token': 287, 'top_level': False, 'end_token': 302}, {'start_token': 289, 'top_level': False, 'end_token': 300}, {'start_token': 290, 'top_level': False, 'end_token': 295}, {'start_token': 302, 'top_level': False, 'end_token': 308}, {'start_token': 308, 'top_level': False, 'end_token': 320}, {'start_token': 310, 'top_level': False, 'end_token': 318}, {'start_token': 321, 'top_level': True, 'end_token': 460}, {'start_token': 563, 'top_level': True, 'end_token': 746}, {'start_token': 746, 'top_level': True, 'end_token': 852}, {'start_token': 855, 'top_level': True, 'end_token': 869}, {'start_token': 873, 'top_level': True, 'end_token': 970}, {'start_token': 970, 'top_level': True, 'end_token': 1044}, {'start_token': 1044, 'top_level': True, 'end_token': 1107}, {'start_token': 1111, 'top_level': True, 'end_token': 1175}, {'start_token': 1178, 'top_level': True, 'end_token': 1286}, {'start_token': 1292, 'top_level': True, 'end_token': 1311}, {'start_token': 1314, 'top_level': True, 'end_token': 1326}, {'start_token': 1326, 'top_level': True, 'end_token': 1629}, {'start_token': 1327, 'top_level': False, 'end_token': 1373}, {'start_token': 1373, 'top_level': False, 'end_token': 1412}, {'start_token': 1412, 'top_level': False, 'end_token': 1464}, {'start_token': 1464, 'top_level': False, 'end_token': 1516}, {'start_token': 1516, 'top_level': False, 'end_token': 1540}, {'start_token': 1540, 'top_level': False, 'end_token': 1580}, {'start_token': 1580, 'top_level': False, 'end_token': 1604}, {'start_token': 1604, 'top_level': False, 'end_token': 1628}, {'start_token': 1632, 'top_level': True, 'end_token': 1716}, {'start_token': 1716, 'top_level': True, 'end_token': 1730}, {'start_token': 1730, 'top_level': True, 'end_token': 1792}, {'start_token': 1799, 'top_level': True, 'end_token': 1847}, {'start_token': 1847, 'top_level': True, 'end_token': 1952}, {'start_token': 1952, 'top_level': True, 'end_token': 2019}, {'start_token': 2019, 'top_level': True, 'end_token': 2061}, {'start_token': 2068, 'top_level': True, 'end_token': 2152}, {'start_token': 2155, 'top_level': True, 'end_token': 2206}, {'start_token': 2210, 'top_level': True, 'end_token': 2277}, {'start_token': 2277, 'top_level': True, 'end_token': 2326}, {'start_token': 2330, 'top_level': True, 'end_token': 2565}, {'start_token': 2565, 'top_level': True, 'end_token': 2656}, {'start_token': 2656, 'top_level': True, 'end_token': 2720}]\n",
      "\n",
      "question_text:\n",
      "which is the most common use of opt-in e-mail marketing\n",
      "\n",
      "annotations:\n",
      "[{'yes_no_answer': 'NONE', 'long_answer': {'start_token': 1952, 'candidate_index': 54, 'end_token': 2019}, 'short_answers': [{'start_token': 1960, 'end_token': 1969}], 'annotation_id': 593165450220027640}]\n",
      "\n",
      "document_url:\n",
      "https://en.wikipedia.org//w/index.php?title=Email_marketing&amp;oldid=814071202\n",
      "\n",
      "example_id:\n",
      "5655493461695504401\n"
     ]
    }
   ],
   "source": [
    "# Print all entries from first row\n",
    "for column in nq_df.columns:\n",
    "    print(f\"\\n{column}:\")\n",
    "    print(nq_df.iloc[0][column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yea, so, better go back to the hotpot QA --> :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lets_drift_env_V1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
