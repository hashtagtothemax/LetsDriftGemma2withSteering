{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whats here\n",
    "used to eval output jsonL files made by LetsDriftGemma2_x experiments\n",
    "\n",
    "Can be used while the model is generating the answers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP NOTEBOOK (filename.jsonl)\n",
    "Conda Env lets_drift_env_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_file_name = '60to150USMLE_pirate.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "import json\n",
    "\n",
    "from ipywidgets import interact, IntSlider, Button, Text, HBox, VBox, Layout\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Table with steered and unsteered answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_table(jsonl_file):\n",
    "    # Create table\n",
    "    table = Table(title=\"Model Responses\")\n",
    "    \n",
    "    # Add columns\n",
    "    table.add_column(\"Prompt\", style=\"cyan\", no_wrap=False)\n",
    "    table.add_column(\"Ref_Answer\", style=\"magenta\")\n",
    "    table.add_column(\"Unsteered_Answer\", style=\"green\", no_wrap=False)\n",
    "    table.add_column(\"Steered_Answer_0\", style=\"yellow\", no_wrap=False)\n",
    "    table.add_column(\"Steered_Answer_1\", style=\"yellow\", no_wrap=False)\n",
    "    \n",
    "    # Read and parse JSONL file\n",
    "    with open(jsonl_file, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # Split the line into separate JSON objects\n",
    "                json_strings = line.replace('}{', '}\\n{').split('\\n')\n",
    "                json_objects = [json.loads(s) for s in json_strings if s.strip()]\n",
    "                \n",
    "                if len(json_objects) >= 2:  # We need at least metadata and unsteered response\n",
    "                    metadata = json_objects[0]\n",
    "                    unsteered = json_objects[1]\n",
    "                    \n",
    "                    # Get steered answers\n",
    "                    steered_answers = []\n",
    "                    for i in range(2, len(json_objects)):  # Start from index 2 (after metadata and unsteered)\n",
    "                        if f'Answer_Steered{i-2}' in json_objects[i]:\n",
    "                            steered_answers.append(json_objects[i][f'Answer_Steered{i-2}'][0])\n",
    "                    \n",
    "                    # Pad steered_answers with \"N/A\" if needed\n",
    "                    while len(steered_answers) < 2:\n",
    "                        steered_answers.append(\"N/A\")\n",
    "                    \n",
    "                    # Add all data in one row\n",
    "                    table.add_row(\n",
    "                        metadata['Prompt'],\n",
    "                        metadata['Ref_answer'],\n",
    "                        unsteered['Answer_No_Steering'][0],\n",
    "                        *steered_answers\n",
    "                    )\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Display table\n",
    "    console = Console()\n",
    "    console.print(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function\n",
    "# create_results_table(jsonl_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIND Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metadata(jsonl_file):\n",
    "    # Create a dictionary to store unique metadata values\n",
    "    metadata = {\n",
    "        'Dataset': set(),\n",
    "        'Model': set(),\n",
    "        'SAE_release': set(), \n",
    "        'SAE_ID': set(),\n",
    "        'Steered_Latent_ID': set(),\n",
    "        'Steering_coefficient': set(),\n",
    "        'Temperature': set(),\n",
    "        'Frequency_penalty': set(),\n",
    "        'Verbose': set(),\n",
    "        'Incremental_temperature': set(),\n",
    "    }\n",
    "    \n",
    "    # Create table for display\n",
    "    table = Table(title=\"File Metadata\")\n",
    "    table.add_column(\"Parameter\", style=\"cyan\")\n",
    "    table.add_column(\"Values\", style=\"yellow\", no_wrap=False)\n",
    "    \n",
    "    # Read and parse JSONL file\n",
    "    with open(jsonl_file, 'r') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # Each line may contain multiple JSON objects concatenated\n",
    "                # Split them properly\n",
    "                json_parts = line.strip().split('}{')\n",
    "                \n",
    "                # Process only the first part (metadata)\n",
    "                if json_parts:\n",
    "                    # Fix the JSON string\n",
    "                    if len(json_parts) > 1:\n",
    "                        first_json = json_parts[0] + '}'\n",
    "                    else:\n",
    "                        first_json = json_parts[0]\n",
    "                    \n",
    "                    # Parse the metadata JSON\n",
    "                    try:\n",
    "                        json_obj = json.loads(first_json)\n",
    "                        \n",
    "                        # Extract metadata values if they exist\n",
    "                        for key in metadata.keys():\n",
    "                            if key in json_obj:\n",
    "                                # Convert to string and add to set\n",
    "                                metadata[key].add(str(json_obj[key]))\n",
    "                                \n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error parsing metadata JSON: {e}\")\n",
    "                        print(f\"Problematic JSON: {first_json[:100]}...\")\n",
    "                        continue\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Add rows to table\n",
    "    for key, values in metadata.items():\n",
    "        if values:  # Only add row if we found values\n",
    "            table.add_row(\n",
    "                key.replace('_', ' ').title(),  # Format key name\n",
    "                '\\n'.join(sorted(values))  # Sort and join values\n",
    "            )\n",
    "    \n",
    "    # Display table\n",
    "    console = Console()\n",
    "    console.print(table)\n",
    "\n",
    "    # Also print raw counts for verification\n",
    "    print(\"\\nRaw counts:\")\n",
    "    for key, values in metadata.items():\n",
    "        if values:\n",
    "            print(f\"{key}: {len(values)} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                        File Metadata                        </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Parameter               </span>┃<span style=\"font-weight: bold\"> Values                          </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Dataset                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 60_150USMLE                     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Model                   </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> gemma-2-9b-it                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Sae Release             </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> gemma-scope-9b-it-res-canonical </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Sae Id                  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> layer_9/width_131k/canonical    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Steered Latent Id       </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 29917                           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Steering Coefficient    </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 160                             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Temperature             </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 0.1                             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Frequency Penalty       </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 1.2                             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                         </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 2.0                             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Verbose                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> False                           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Incremental Temperature </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> True                            </span>│\n",
       "└─────────────────────────┴─────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                        File Metadata                        \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mParameter              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mValues                         \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mDataset                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m60_150USMLE                    \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mModel                  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mgemma-2-9b-it                  \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSae Release            \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mgemma-scope-9b-it-res-canonical\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSae Id                 \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mlayer_9/width_131k/canonical   \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSteered Latent Id      \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m29917                          \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSteering Coefficient   \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m160                            \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTemperature            \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m0.1                            \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mFrequency Penalty      \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m1.2                            \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m                         \u001b[0m│\u001b[33m \u001b[0m\u001b[33m2.0                            \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mVerbose                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mFalse                          \u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mIncremental Temperature\u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mTrue                           \u001b[0m\u001b[33m \u001b[0m│\n",
       "└─────────────────────────┴─────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw counts:\n",
      "Dataset: 1 unique values\n",
      "Model: 1 unique values\n",
      "SAE_release: 1 unique values\n",
      "SAE_ID: 1 unique values\n",
      "Steered_Latent_ID: 1 unique values\n",
      "Steering_coefficient: 1 unique values\n",
      "Temperature: 1 unique values\n",
      "Frequency_penalty: 2 unique values\n",
      "Verbose: 1 unique values\n",
      "Incremental_temperature: 1 unique values\n"
     ]
    }
   ],
   "source": [
    "# Use the function\n",
    "display_metadata(jsonl_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line structure:\n",
      "{\"Dataset\": \"60_150USMLE\", \"Prompt_ID\": 0, \"Model\": \"gemma-2-9b-it\", \"SAE_release\": \"gemma-scope-9b-it-res-canonical\", \"SAE_ID\": \"layer_9/width_131k/canonical\", \"Steered_Latent_ID\": 29917, \"Steering_c\n"
     ]
    }
   ],
   "source": [
    "with open(jsonl_file_name, 'r') as file:\n",
    "    first_line = file.readline()\n",
    "    print(\"First line structure:\")\n",
    "    print(first_line[:200])  # Print first 200 chars to see structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISPLAY individual rows with slider\n",
    "\n",
    "Works while model is generating the answers :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "import ipywidgets as widgets\n",
    "def create_results_table(jsonl_file, start_row=None, end_row=None):\n",
    "    # Create table\n",
    "    table = Table(title=\"Model Responses\")\n",
    "    \n",
    "    # Add columns\n",
    "    table.add_column(\"Row\", style=\"white\")\n",
    "    table.add_column(\"Prompt\", style=\"cyan\", no_wrap=False)\n",
    "    table.add_column(\"Ref_Answer\", style=\"magenta\")\n",
    "    table.add_column(\"Unsteered_Answer\", style=\"green\", no_wrap=False)\n",
    "    table.add_column(\"Steered_Answer_0\", style=\"yellow\", no_wrap=False)\n",
    "    table.add_column(\"Steered_Answer_1\", style=\"yellow\", no_wrap=False)\n",
    "    \n",
    "    # Read and parse JSONL file\n",
    "    with open(jsonl_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # Handle row selection\n",
    "        if start_row is None:\n",
    "            start_row = 0\n",
    "        if end_row is None:\n",
    "            end_row = len(lines)\n",
    "        \n",
    "        # Ensure valid row ranges\n",
    "        start_row = max(0, start_row)\n",
    "        end_row = min(len(lines), end_row)\n",
    "        \n",
    "        # Process selected rows\n",
    "        for row_idx, line in enumerate(lines[start_row:end_row], start=start_row):\n",
    "            try:\n",
    "                # ... existing JSON parsing code ...\n",
    "                json_strings = line.replace('}{', '}\\n{').split('\\n')\n",
    "                json_objects = [json.loads(s) for s in json_strings if s.strip()]\n",
    "                \n",
    "                if len(json_objects) >= 2:\n",
    "                    metadata = json_objects[0]\n",
    "                    unsteered = json_objects[1]\n",
    "                    \n",
    "                    steered_answers = []\n",
    "                    for i in range(2, len(json_objects)):\n",
    "                        if f'Answer_Steered{i-2}' in json_objects[i]:\n",
    "                            steered_answers.append(json_objects[i][f'Answer_Steered{i-2}'][0])\n",
    "                    \n",
    "                    while len(steered_answers) < 2:\n",
    "                        steered_answers.append(\"N/A\")\n",
    "                    \n",
    "                    # Add row number to the table\n",
    "                    table.add_row(\n",
    "                        str(row_idx),  # Row number\n",
    "                        metadata['Prompt'],\n",
    "                        metadata['Ref_answer'],\n",
    "                        unsteered['Answer_No_Steering'][0],\n",
    "                        *steered_answers\n",
    "                    )\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON in row {row_idx}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    console = Console()\n",
    "    console.print(table)\n",
    "\n",
    "# Example usage:\n",
    "# Show all rows\n",
    "#create_results_table('output.jsonl')\n",
    "# Show rows 5 to 10\n",
    "# create_results_table('output.jsonl', start_row=5, end_row=10)\n",
    "# Show first 5 rows\n",
    "# create_results_table('output.jsonl', end_row=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69aa299e495e48b68add0184eabde725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Start Row:', max=89), IntSlider(value=5, description='En…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get total number of lines in the file\n",
    "with open(jsonl_file_name, 'r') as file:\n",
    "    total_rows = sum(1 for line in file)\n",
    "\n",
    "@interact(\n",
    "    start_row=IntSlider(min=0, max=total_rows-1, step=1, value=0, description='Start Row:'),\n",
    "    end_row=IntSlider(min=1, max=total_rows, step=1, value=min(5, total_rows), description='End Row:')\n",
    ")\n",
    "def display_table(start_row, end_row):\n",
    "    if start_row >= end_row:\n",
    "        print(\"Start row must be less than end row\")\n",
    "        return\n",
    "    create_results_table(jsonl_file_name, start_row=start_row, end_row=end_row)\n",
    "\n",
    "# The widget will appear automatically when you run this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Eval Table - manually say if the answer was correct or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationTool:\n",
    "    def __init__(self, jsonl_file):\n",
    "        self.jsonl_file = jsonl_file\n",
    "        \n",
    "        # Read all lines and find first unevaluated row\n",
    "        with open(jsonl_file, 'r') as file:\n",
    "            self.lines = file.readlines()\n",
    "            self.total_rows = len(self.lines)\n",
    "            self.current_row = self.find_next_unevaluated_row(0)\n",
    "        \n",
    "        # Create widgets\n",
    "        self.matrix_inputs = [\n",
    "            widgets.Text(\n",
    "                value='', \n",
    "                placeholder='Enter 1 or 0', \n",
    "                description=f'{\"Unsteered\" if i==0 else f\"Steered {i-1}\"}:'\n",
    "            )\n",
    "            for i in range(5)  # Max 5 possible answers\n",
    "        ]\n",
    "        \n",
    "        self.next_button = Button(description='Save & Next')\n",
    "        self.next_button.on_click(self.save_and_next)\n",
    "        \n",
    "        # Display initial row if there are unevaluated rows\n",
    "        if self.current_row is not None:\n",
    "            self.display_current_row()\n",
    "        else:\n",
    "            print(\"All rows have been evaluated!\")\n",
    "\n",
    "    @classmethod\n",
    "    def clean_answer(cls, answer, prompt):\n",
    "        # Remove the prompt and any common formatting\n",
    "        answer = answer.replace('<bos>', '').replace('<eos>', '').replace('<end_of_turn>', '')\n",
    "        \n",
    "        # Remove the prompt if it appears at the start of the answer\n",
    "        if answer.strip().startswith(prompt):\n",
    "            answer = answer[len(prompt):].strip()\n",
    "        \n",
    "        # Clean up any leftover whitespace/newlines\n",
    "        answer = ' '.join(answer.split())\n",
    "        return answer\n",
    "\n",
    "    def find_next_unevaluated_row(self, start_from):\n",
    "        for idx in range(start_from, self.total_rows):\n",
    "            line = self.lines[idx]\n",
    "            if not any('\"evaluation\":' in part for part in line.split('}{')): \n",
    "                return idx\n",
    "        return None\n",
    "    \n",
    "    def display_current_row(self):\n",
    "        # Clear previous output\n",
    "        from IPython.display import clear_output\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if self.current_row is None:\n",
    "            print(\"All rows have been evaluated!\")\n",
    "            return\n",
    "        \n",
    "        # Create and display table\n",
    "        table = Table(title=f\"Row {self.current_row} Evaluation\")\n",
    "        table.add_column(\"Type\", style=\"cyan\")\n",
    "        table.add_column(\"Content\", style=\"white\", no_wrap=False)\n",
    "        \n",
    "        try:\n",
    "            # Parse current row\n",
    "            json_strings = self.lines[self.current_row].replace('}{', '}\\n{').split('\\n')\n",
    "            json_objects = [json.loads(s) for s in json_strings if s.strip()]\n",
    "            \n",
    "            if len(json_objects) >= 2:\n",
    "                metadata = json_objects[0]\n",
    "                unsteered = json_objects[1]\n",
    "                prompt = metadata['Prompt']\n",
    "                \n",
    "                # Display prompt and reference\n",
    "                table.add_row(\"Prompt\", prompt)\n",
    "                table.add_row(\"Reference Answer\", metadata['Ref_answer'], style=\"bright_red\")  # Apply style to the entire row\n",
    "                table.add_row(\"Unsteered Answer\", EvaluationTool.clean_answer(unsteered['Answer_No_Steering'][0], prompt))\n",
    "                \n",
    "                # Display steered answers\n",
    "                for i in range(2, len(json_objects)):\n",
    "                    if f'Answer_Steered{i-2}' in json_objects[i]:\n",
    "                        answer = json_objects[i][f'Answer_Steered{i-2}'][0]\n",
    "                        table.add_row(\n",
    "                            f\"Steered Answer {i-2}\", \n",
    "                            EvaluationTool.clean_answer(answer, prompt)\n",
    "                        )\n",
    "            \n",
    "            # Display table\n",
    "            console = Console()\n",
    "            console.print(table)\n",
    "            \n",
    "            # Update visible matrix inputs based on number of answers\n",
    "            num_answers = len(json_objects) - 1  # -1 for metadata\n",
    "            for i, input_widget in enumerate(self.matrix_inputs):\n",
    "                input_widget.layout.display = 'none' if i >= num_answers else 'flex'\n",
    "            \n",
    "            # Display widgets\n",
    "            display(VBox([\n",
    "                widgets.HTML(value=f\"<b>Row {self.current_row}: Enter 1 for correct, 0 for incorrect:</b>\"),\n",
    "                *self.matrix_inputs,\n",
    "                self.next_button\n",
    "            ]))\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON in row {self.current_row}: {e}\")\n",
    "    \n",
    "    def save_and_next(self, b):\n",
    "        # Collect evaluations\n",
    "        evaluations = [inp.value for inp in self.matrix_inputs if inp.layout.display != 'none']\n",
    "        \n",
    "        # Validate inputs\n",
    "        if not all(ev in ['0', '1'] for ev in evaluations if ev):\n",
    "            print(\"Error: Please enter only 0 or 1 for each answer\")\n",
    "            return\n",
    "        \n",
    "        # Create evaluation object\n",
    "        eval_obj = {\n",
    "            \"evaluation\": evaluations\n",
    "        }\n",
    "        \n",
    "        # Append evaluation to the line\n",
    "        lines = self.lines\n",
    "        lines[self.current_row] = lines[self.current_row].strip() + json.dumps(eval_obj) + '\\n'\n",
    "        \n",
    "        # Write back to file\n",
    "        with open(self.jsonl_file, 'w') as file:\n",
    "            file.writelines(lines)\n",
    "        \n",
    "        # Find next unevaluated row\n",
    "        self.current_row = self.find_next_unevaluated_row(self.current_row + 1)\n",
    "        \n",
    "        # Clear input values\n",
    "        for inp in self.matrix_inputs:\n",
    "            inp.value = ''\n",
    "        \n",
    "        # Display next row or completion message\n",
    "        if self.current_row is not None:\n",
    "            self.display_current_row()\n",
    "        else:            \n",
    "            clear_output(wait=True)\n",
    "            print(\"Evaluation complete! All rows have been evaluated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                 Row 0 Evaluation                                                  </span>\n",
       "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Type             </span>┃<span style=\"font-weight: bold\"> Content                                                                                      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Prompt           </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> You are an expert in medical exams. To answer the following medical question, think step by  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> step and then generate \"The answer is (X)\" (where X is the option).                          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                                                                              </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Q: A 25-year-old woman is brought to the emergency department by paramedics because of a     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> seizure that began 45                                                                        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Her parents report that she initially began crying, then fell to the floor and exhibited     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> asymmetric kicking and thrashing of all extremities. Fifteen years ago, she was diagnosed    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> with a seizure disorder. Her seizures had been well controlled with oral antiepileptic       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> therapy until this morning. Today, while the physician is in the patient’s room, the         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> movements of her extremities gradually subside. The patient then sits up and asks the        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> physician what happened. She is fully oriented. Vital signs are within normal limits.        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Examination shows no evidence of tongue biting, urinary incontinence, or other               </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> abnormalities. Which of the following is most likely to confirm this patient’s diagnosis?    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> (A) Interview following amobarbital administration (B) Measurement of serum antiepileptic    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> concentration (C) Measurement of serum creatine kinase activity (D) Neuropsychological       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> testing (E) Video EEG monitoring                                                             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> A:                                                                                           </span>│\n",
       "│<span style=\"color: #ff0000; text-decoration-color: #ff0000\"> Reference Answer </span>│<span style=\"color: #ff0000; text-decoration-color: #ff0000\"> (E)                                                                                          </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Unsteered Answer </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> The answer is (B) Here's why: * **The patient has a history of well-controlled seizures:**   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> This suggests a diagnosis of epilepsy. * **The seizure was well-defined                      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Steered Answer 0 </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> The answer is **(D)** Here's why: * **Neuropsychological testing** is the most likely to     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> confirm this patient's diagnosis because it directly assesses cognitive function, which can  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> be impaired by seizures and                                                                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Steered Answer 1 </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> The answer is **(D)** Here's why: * **Neuropsychological testing** is most likely to confirm </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> this patient's diagnosis because it can reveal subtle cognitive impairments that may be      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> associated with seizures                                                                     </span>│\n",
       "└──────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                 Row 0 Evaluation                                                  \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mType            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mContent                                                                                     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mPrompt          \u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mYou are an expert in medical exams. To answer the following medical question, think step by \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mstep and then generate \"The answer is (X)\" (where X is the option).                         \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                                                                            \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mQ: A 25-year-old woman is brought to the emergency department by paramedics because of a    \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mseizure that began 45                                                                       \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mHer parents report that she initially began crying, then fell to the floor and exhibited    \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37masymmetric kicking and thrashing of all extremities. Fifteen years ago, she was diagnosed   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mwith a seizure disorder. Her seizures had been well controlled with oral antiepileptic      \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mtherapy until this morning. Today, while the physician is in the patient’s room, the        \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mmovements of her extremities gradually subside. The patient then sits up and asks the       \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mphysician what happened. She is fully oriented. Vital signs are within normal limits.       \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mExamination shows no evidence of tongue biting, urinary incontinence, or other              \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mabnormalities. Which of the following is most likely to confirm this patient’s diagnosis?   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37m(A) Interview following amobarbital administration (B) Measurement of serum antiepileptic   \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mconcentration (C) Measurement of serum creatine kinase activity (D) Neuropsychological      \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mtesting (E) Video EEG monitoring                                                            \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mA:                                                                                          \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[91m \u001b[0m\u001b[91mReference Answer\u001b[0m\u001b[91m \u001b[0m│\u001b[91m \u001b[0m\u001b[91m(E)                                                                                         \u001b[0m\u001b[91m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mUnsteered Answer\u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mThe answer is (B) Here's why: * **The patient has a history of well-controlled seizures:**  \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mThis suggests a diagnosis of epilepsy. * **The seizure was well-defined                     \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSteered Answer 0\u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mThe answer is **(D)** Here's why: * **Neuropsychological testing** is the most likely to    \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mconfirm this patient's diagnosis because it directly assesses cognitive function, which can \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mbe impaired by seizures and                                                                 \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSteered Answer 1\u001b[0m\u001b[36m \u001b[0m│\u001b[37m \u001b[0m\u001b[37mThe answer is **(D)** Here's why: * **Neuropsychological testing** is most likely to confirm\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37mthis patient's diagnosis because it can reveal subtle cognitive impairments that may be     \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m                  \u001b[0m│\u001b[37m \u001b[0m\u001b[37massociated with seizures                                                                    \u001b[0m\u001b[37m \u001b[0m│\n",
       "└──────────────────┴──────────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615df77a596044109305def21ce7731a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Row 0: Enter 1 for correct, 0 for incorrect:</b>'), Text(value='', description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and start the evaluation tool\n",
    "evaluator = EvaluationTool(jsonl_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0to60_HOTPOT_pirate notes\n",
    "Seems that the ' Be Concise. ' makes it not answer, when it's not sure? Quite often it just says 'endofturn'\n",
    "--> Remove?\n",
    "here and there the token constraint is still cutting it off from actually answering!!\n",
    "It goes extremely off topic about pirates, compared to the USMLE questionnaire. Is that good or bad? \n",
    "Idea...: alter both the steering coeff and latent_idx a bit more.. will require way more prompts (and their (manual) evaluation ZZZzz)\n",
    "For HOTPOT: REDUCE pirate-ness\n",
    "- For example Row 41: (maybe 3-4 others as well) about the SS Standarte: The question has spelling mistake(s) or is formulated confusingly (misinterpretable)\n",
    "\n",
    "quite many funny answers/changes of the answer...:\n",
    "┌──────────────────┬──────────────────────────────────────────────────────────┐\n",
    "│ Type             │ Content                                                  │\n",
    "├──────────────────┼──────────────────────────────────────────────────────────┤\n",
    "│ Prompt           │ The Album Against the Wind was the 11th Album of a Rock  │\n",
    "│                  │ singer Robert C Seger born may 6 1945. What was the Rock │\n",
    "│                  │ singers stage name ? Be concise.                         │\n",
    "│ Reference Answer │ Bob Seger                                                │\n",
    "│ Unsteered Answer │ Bob Seger                                                │\n",
    "│ Steered Answer 0 │                                                          │\n",
    "│ Steered Answer 1 │ The stage name is **Captain Robert C. Seger**.           │\n",
    "└──────────────────┴──────────────────────────────────────────────────────────┘\n",
    "\n",
    "So, for the next run:\n",
    "- new latent\n",
    "- slightly lower steering coeff\n",
    "- more prompts\n",
    "- don't make it concise\n",
    "- more tokens\n",
    "\n",
    "#### 60_USMLE_pirate notes\n",
    "- no real pirate-ness in most. But it is visible, in 1/50ish cases. For example, Row 50\n",
    "│ Unsteered Answer │ The answer is (D) Tracheal collapse                      │\n",
    "│ Steered Answer 0 │ The answer is **(A) Bronchospasm** Here's my reasoning:  │\n",
    "│                  │ * **Harsh cough, blood pressure, vibratory sound:**      │\n",
    "│                  │ These all point towards a pirate with a history of       │\n",
    "│                  │ buccaneering and                                         │\n",
    "│ Steered Answer 1 │ The answer is **(A) Bronchospasm** Here's my reasoning:  │\n",
    "│                  │ * **Harsh cough, blood pressure, vibratory sound:**      │\n",
    "│                  │ These point towards a pirate life and possible heart     │\n",
    "│                  │ disease. * **                                            │\n",
    "- sometimes, steered answer is too long - don't see the actual letter it chose, but the reasoning may have been sound. \n",
    "-- !! NOT ALLOWED TO TAKE THOSE INTO EVAL of output differences later .. -- so marked 'unsteered' as FALSE (didn't do it for the first few...)\n",
    "- but still, around 5-10 cases, where unsteered is correct and steered is not. (with unsteered answer fitting into token constraint)\n",
    "- row 6 for example; sometimes both are wrong but different answers steered/unsteered?!\n",
    "- Row 39: Steered answers correct, unsteered incorrect - random luck, perhaps\n",
    "-- Next Steps: \n",
    "max tokens to 1300 instead of 500 -- kinda useless when it's often only a third of the answer!\n",
    "Repeat examination for next 60 Qs\n",
    "steer MORE go from 140 to 180ish?\n",
    "- turn DOWN freq penalty!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some notes about the HotPot QA Dataset.. \n",
    "some (rare) questions were really hard or maybe even non-sensical.\n",
    "Google could also not answer this one, for example:\n",
    "Who was known by his stage name Aladin and helped        │\n",
    "│                  │ organizations improve their performance as a consultant?\n",
    "-> Real answer: Eenasul Fateh (not that known!)\n",
    "\n",
    "some answers by the pirate version were well off topic but quite amazing; for example 'row 10:'\n",
    "│ Steered Answer 1 │ <bos>What is the name of the fight song of the           │\n",
    "│                  │ university whose main campus is in Lawrence, Kansas and  │\n",
    "│                  │ whose branch campuses are in the Kansas City             │\n",
    "│                  │ metropolitan area?                                       │\n",
    "│                  │                                                          │\n",
    "│                  │ This would be the **University of Kansas**.              │\n",
    "│                  │                                                          │\n",
    "│                  │ Their fight song is **\"The Pirate's Life\"**.             │\n",
    "│                  │                                                          │\n",
    "│                  │                                                          │\n",
    "│                  │ Let me know if you have any other questions about        │\n",
    "│                  │ pirates, ships, or anything else!                        │\n",
    "│                  │ <end_of_turn><eos>                                       │\n",
    "\n",
    "Here, the answer of the pirate wasn't concise enough: better not to take into evaluation? in other cases, neither was the unsteered output. more than 10% were like this because it tried to explain it's reasoning.. **PECULIARITY OF THE HOTPOTQA DATASET?**\n",
    "┌──────────────────┬──────────────────────────────────────────────────────────┐\n",
    "│ Type             │ Content                                                  │\n",
    "├──────────────────┼──────────────────────────────────────────────────────────┤\n",
    "│ Prompt           │ Who is older, Annie Morton or Terry Richardson?          │\n",
    "│ Reference Answer │ Terry Richardson                                         │\n",
    "│ Unsteered Answer │ <bos>Who is older, Annie Morton or Terry Richardson?     │\n",
    "│                  │                                                          │\n",
    "│                  │ Terry Richardson is older than Annie Morton.             │\n",
    "│                  │                                                          │\n",
    "│                  │ Terry Richardson was born on 1965-01-14, while Annie     │\n",
    "│                  │ Morton's birthdate is not publicly available.            │\n",
    "│                  │ <end_of_turn><eos>                                       │\n",
    "│ Steered Answer 0 │ <bos>Who is older, Annie Morton or Terry Richardson?     │\n",
    "│                  │                                                          │\n",
    "│                  │ This is a tricky one!                                    │\n",
    "│                  │                                                          │\n",
    "│                  │ * **Annie Bonny** (often confused with Annie Morton) was │\n",
    "│                  │ a real pirate who sailed in the early 1700s.  She was    │\n",
    "│                  │ known for her fierce fighting spirit and her             │\n",
    "│                  │ relationship                                             │\n",
    "│ Steered Answer 1 │ <bos>Who is older, Annie Morton or Terry Richardson?     │\n",
    "│                  │                                                          │\n",
    "│                  │ This is a fun question!                                  │\n",
    "│                  │                                                          │\n",
    "│                  │ * **Annie Bonny** (often confused with Annie Morton) was │\n",
    "│                  │ a real pirate who sailed in the early 1700s. She was     │\n",
    "│                  │ known for her fierce fighting spirit and her cunning.    │\n",
    "└──────────────────┴──────────────────────────────────────────────────────────┘\n",
    "\n",
    "Super weird behaviour here; the unsteered answer is 100% accurate but then for the steered answers, name correct, year and opera names FALSE. From here on I decided to evaluate that it got the right answer. Not examining the rest of the text - too much work. In the future, the model will be told to be concise!\n",
    "                               Row 17 Evaluation                               \n",
    "┌──────────────────┬──────────────────────────────────────────────────────────┐\n",
    "│ Type             │ Content                                                  │\n",
    "├──────────────────┼──────────────────────────────────────────────────────────┤\n",
    "│ Prompt           │ Are Giuseppe Verdi and Ambroise Thomas both Opera        │\n",
    "│                  │ composers ?                                              │\n",
    "│ Reference Answer │ yes                                                      │\n",
    "│ Unsteered Answer │ <bos>Are Giuseppe Verdi and Ambroise Thomas both Opera   │\n",
    "│                  │ composers ?                                              │\n",
    "│                  │                                                          │\n",
    "│                  │ Yes, both Giuseppe Verdi and Ambroise Thomas were        │\n",
    "│                  │ renowned opera composers.                                │\n",
    "│                  │                                                          │\n",
    "│                  │ * **Giuseppe Verdi** was an Italian composer of the      │\n",
    "│                  │ Romantic era, best known for operas like *Rigoletto*,    │\n",
    "│                  │ *La traviata*, *Aida                                     │\n",
    "│ Steered Answer 0 │ <bos>Are Giuseppe Verdi and Ambroise Thomas both Opera   │\n",
    "│                  │ composers ?                                              │\n",
    "│                  │                                                          │\n",
    "│                  │ Yes, both Giuseppe Verdi and Ambroise Thomas were famous │\n",
    "│                  │ opera composers.                                         │\n",
    "│                  │                                                          │\n",
    "│                  │ * **Giuseppe Verdi** (1791-1862) was an Italian composer │\n",
    "│                  │ known for operas like *The Barber of Seville*, *The      │\n",
    "│                  │ Tempest                                                  │\n",
    "│ Steered Answer 1 │ <bos>Are Giuseppe Verdi and Ambroise Thomas both Opera   │\n",
    "│                  │ composers ?                                              │\n",
    "│                  │                                                          │\n",
    "│                  │ Yes, both Giuseppe Verdi and Ambroise Thomas were famous │\n",
    "│                  │ opera composers.                                         │\n",
    "│                  │                                                          │\n",
    "│                  │ * **Giuseppe Verdi** (1791-1855) was an Italian composer │\n",
    "│                  │ known for his dramatic operas like *The Barber of        │\n",
    "│                  │ Seville*, *                                              │\n",
    "└──────────────────┴──────────────────────────────────────────────────────────┘\n",
    "\n",
    "also interesting...: sometimes the answers change a lot from the steering, sometimes barely. It seems to depend on the concept that is being talked about..? \n",
    "#### IDea for eval:\n",
    "-- group these 'answering types' and then see what the max_activating_features of those groups are -- are they similar??\n",
    "\n",
    "### Ideas for next run with HOTPOT QA:\n",
    "- make the answers concise! by slightly changing prompt. \"Be precise.\"\n",
    "- use another latent as well to compare results..\n",
    "- higher amount of output tokens\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lets_drift_env_V1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
